{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6LDaZEio73J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PowerTransformer, Normalizer, MaxAbsScaler, RobustScaler, QuantileTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "def power_transform(df, method):\n",
        "    if(method == 'yeo'):\n",
        "      power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
        "      df = power.fit_transform(df)\n",
        "      return df\n",
        "    elif(method == 'box'):\n",
        "      power = PowerTransformer(method='box-cox', standardize=True)\n",
        "      df = power.fit_transform(df)\n",
        "      return df\n",
        "    else:\n",
        "      return \"ENTER IN yeo OR box\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('soil-moisture.csv')"
      ],
      "metadata": {
        "id": "YVkoaA3bo_dL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('Day', axis = 1)\n"
      ],
      "metadata": {
        "id": "cZhD5ZwBpThZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Month'].unique()"
      ],
      "metadata": {
        "id": "g3VWoJA5pXkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spring(rows):\n",
        "  if(rows == 'Jul' or rows == 'Aug' or rows == 'Sep'):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def fall(rows):\n",
        "  if(rows == 'Oct' or rows == 'Nov'):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def winter(rows):\n",
        "  if(rows == 'Dec' or rows == 'Jan' or rows == 'Feb'):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "def summer(rows):\n",
        "  if(rows == 'Mar'):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "df['spring'] = df['Month'].apply(spring)\n",
        "df['winter'] = df['Month'].apply(winter)\n",
        "df['fall'] = df['Month'].apply(fall)\n",
        "df['summer'] = df['Month'].apply(summer)"
      ],
      "metadata": {
        "id": "IdAAarFCpaBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('Month', axis = 1)"
      ],
      "metadata": {
        "id": "VO4MvPzltBAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('avg_sm', axis = 1)\n",
        "y = df['avg_sm']"
      ],
      "metadata": {
        "id": "uFqLKi2xtEY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_continuous = X.drop(['spring', 'winter', 'fall', 'summer'], axis = 1)\n",
        "X_discrete = X[['spring', 'winter', 'fall', 'summer']]\n",
        "X_continuous_yeo = power_transform(X_continuous, 'yeo')\n",
        "X_continuous_yeo = pd.DataFrame(X_continuous_yeo, columns = X_continuous.columns)\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_continuous_minmax_scaled = scaler.fit_transform(X_continuous)\n",
        "X_continuous_minmax_scaled = pd.DataFrame(X_continuous_minmax_scaled, columns = X_continuous.columns)\n",
        "\n",
        "scaler2 = StandardScaler()\n",
        "X_continuous_standard_scaled = scaler2.fit_transform(X_continuous)\n",
        "X_continuous_standard_scaled = pd.DataFrame(X_continuous_minmax_scaled, columns = X_continuous.columns)\n",
        "\n",
        "scaler3 = RobustScaler()\n",
        "X_continuous_robust_scaled = scaler3.fit_transform(X_continuous)\n",
        "X_continuous_robust_scaled = pd.DataFrame(X_continuous_robust_scaled, columns = X_continuous.columns)\n",
        "\n",
        "scaler4 = MaxAbsScaler()\n",
        "X_continuous_maxabs_scaled = scaler4.fit_transform(X_continuous)\n",
        "X_continuous_maxabs_scaled = pd.DataFrame(X_continuous_maxabs_scaled, columns = X_continuous.columns)\n",
        "\n",
        "scaler5 = QuantileTransformer()\n",
        "X_continuous_quantile_scaled = scaler5.fit_transform(X_continuous)\n",
        "X_continuous_quantile_scaled = pd.DataFrame(X_continuous_quantile_scaled, columns = X_continuous.columns)\n",
        "\n",
        "scaler6 = Normalizer()\n",
        "X_continuous_normalized = scaler6.fit_transform(X_continuous)\n",
        "X_continuous_normalized = pd.DataFrame(X_continuous_normalized, columns = X_continuous.columns)\n",
        "\n",
        "scaler7 = PCA()\n",
        "X_continuous_pca = scaler7.fit_transform(X_continuous)\n",
        "X_continuous_pca = pd.DataFrame(X_continuous_pca, columns = X_continuous.columns)"
      ],
      "metadata": {
        "id": "ywncusTtXjZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_full_yeo = pd.concat([X_continuous_yeo, X_discrete], axis = 1)\n",
        "X_full_minmax_scaled = pd.concat([X_continuous_minmax_scaled, X_discrete], axis = 1)\n",
        "X_full_standard_scaled = pd.concat([X_continuous_standard_scaled, X_discrete], axis = 1)\n",
        "X_full_robust_scaled = pd.concat([X_continuous_robust_scaled, X_discrete], axis = 1)\n",
        "X_full_maxabs_scaled = pd.concat([X_continuous_maxabs_scaled, X_discrete], axis = 1)\n",
        "X_full_quantile_scaled = pd.concat([X_continuous_quantile_scaled, X_discrete], axis = 1)\n",
        "X_full_normalized = pd.concat([X_continuous_normalized, X_discrete], axis = 1)\n",
        "X_full_pca = pd.concat([X_continuous_pca, X_discrete], axis = 1)\n"
      ],
      "metadata": {
        "id": "jJRyh2kcZMmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_yeo, X_test_yeo, y_train_yeo, y_test_yeo = train_test_split(X_full_yeo, y, test_size = 0.2)\n",
        "X_train_minmax, X_test_minmax, y_train_minmax, y_test_minmax = train_test_split(X_full_minmax_scaled, y, test_size = 0.2)\n",
        "X_train_standard, X_test_standard, y_train_standard, y_test_standard = train_test_split(X_full_standard_scaled, y, test_size = 0.2)\n",
        "X_train_robust, X_test_robust, y_train_robust, y_test_robust = train_test_split(X_full_robust_scaled, y, test_size = 0.2)\n",
        "X_train_maxabs, X_test_maxabs, y_train_maxabs, y_test_maxabs = train_test_split(X_full_maxabs_scaled, y, test_size = 0.2)\n",
        "X_train_quantile, X_test_quantile, y_train_quantile, y_test_quantile = train_test_split(X_full_quantile_scaled, y, test_size = 0.2)\n",
        "X_train_normalized, X_test_normalized, y_train_normalized, y_test_normalized = train_test_split(X_full_normalized, y, test_size = 0.2)\n",
        "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(X_full_pca, y, test_size = 0.2)"
      ],
      "metadata": {
        "id": "3udy36vUuA2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(bootstrap = False, max_depth = 80, max_features = 'sqrt', min_samples_leaf = 2, min_samples_split = 2, n_estimators=200)\n",
        "lister = [rf]\n",
        "datasets = [\n",
        "    [X_train_yeo, X_test_yeo, y_train_yeo, y_test_yeo],\n",
        "    [X_train_minmax, X_test_minmax, y_train_minmax, y_test_minmax],\n",
        "    [X_train_standard, X_test_standard, y_train_standard, y_test_standard],\n",
        "    [X_train_robust, X_test_robust, y_train_robust, y_test_robust],\n",
        "    [X_train_maxabs, X_test_maxabs, y_train_maxabs, y_test_maxabs],\n",
        "    [X_train_quantile, X_test_quantile, y_train_quantile, y_test_quantile],\n",
        "    [X_train_normalized, X_test_normalized, y_train_normalized, y_test_normalized],\n",
        "    [X_train_pca, X_test_pca, y_train_pca, y_test_pca],\n",
        "]\n",
        "for model in lister:\n",
        "  for data in datasets:\n",
        "    X_train = data[0]\n",
        "    X_test = data[1]\n",
        "    y_train = data[2]\n",
        "    y_test = data[3]\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    if(i == 0):\n",
        "      print(\"YEO: \")\n",
        "    elif(i ==1):\n",
        "      print(\"MINMAX: \")\n",
        "    elif(i == 2):\n",
        "      print(\"STANDARD: \")\n",
        "    elif(i == 3):\n",
        "      print(\"ROBUST: \")\n",
        "    elif(i == 4):\n",
        "      print(\"MAXABS: \")\n",
        "    elif(i == 5):\n",
        "      print(\"QUANTILE: \")\n",
        "    elif(i == 6):\n",
        "      print(\"NORMALIZED\")\n",
        "    else:\n",
        "      print(\"PCA: \")\n",
        "    print(mean_squared_error(y_test, y_pred))\n",
        "    print(mean_absolute_error(y_test, y_pred))\n",
        "    print(r2_score(y_test, y_pred))\n",
        "    print()"
      ],
      "metadata": {
        "id": "3k-rZ613uqF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n"
      ],
      "metadata": {
        "id": "FghfSKDwvD5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "rf = RandomForestRegressor()\n",
        "# Random search of parameters, using 3 fold cross validation,\n",
        "# search across 100 different combinations, and use all available cores\n",
        "rf_random = GridSearchCV(estimator = rf, param_grid = random_grid, cv = 3, verbose=2, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train, y_train)\n",
        "rf_random.best_params_\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZct_tA9vMu0",
        "outputId": "42cb9874-f2f6-41cd-d430-f4f8d497af04"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 4320 candidates, totalling 12960 fits\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}